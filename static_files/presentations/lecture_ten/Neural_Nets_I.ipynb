{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f48bc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks I  \n",
    "\n",
    "## Building Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838fbd0",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- Part I: building blocks (today!)\n",
    "- Part II: Convolutional Neural networks, transformer (Monday, July 21)\n",
    "- Part III: Neural networks in unsupervised learning and reinforcement learning (Monday July 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04614d20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## History  \n",
    "\n",
    "| Year | Milestone | What changed? |  \n",
    "|------|-----------|---------------|  \n",
    "| 1943 | McCulloch–Pitts neuron | Binary logic with weighted sums |  \n",
    "| 1958 | Rosenblatt Perceptron | First learning rule for a single neuron |  \n",
    "| 1986 | Rumelhart–Hinton–Williams | Back‑propagation revives multilayer nets |  \n",
    "| 2006 | Hinton’s deep belief nets | Unsupervised pre‑training enables depth |  \n",
    "| 2012 | AlexNet wins ImageNet | GPUs + ReLU ignite the deep‑learning boom |  \n",
    "| 2018‑25 | Foundation models | GPT, AlphaFold, Claude, Gemini ...|  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ddf51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perceptron (McCulloch–Pitts)\n",
    "\n",
    "Formulation:\n",
    "$$y=\\color{lightblue}{\\phi} \\left( \\color{red}{w_1} {x_1} \\color{lightblue}{+}\\color{red}{w_2} x_2 \\color{lightblue}{+} \\ldots\\color{lightblue}{+}\\color{red}{w_m} x_m \\color{lightblue}{+} \\color{red}{b} \\right)  $$\n",
    "\n",
    "- Motivated by biological neurons\n",
    "- Key words: weights $\\color{red}{w_{j}}$, offset $\\color{red}{b}$, activation function $\\color{lightblue}{\\phi(\\cdot)}$\n",
    "<p align=\"center\">\n",
    "  <img src=\"./figures/perceptron.png\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Try out different perceptrons in [Tensorflow playground](https://playground.tensorflow.org/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1449f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi‑Layer Perceptron (MLP)  \n",
    "\n",
    "Multi-layer perceptron, or feed‑forward neural network, is a chain of linear layers plus nonlinear activations, for hidden layer $l=1,2,\\ldots,L$,\n",
    "$$ \\mathbf{z}^{(l)} = \\phi\\left(\\color{red}{\\mathbf{W}^{(l)}}\\,\\mathbf{z}^{(l-1)} + \\color{red}{\\mathbf{b}^{(l)}}\\right), $$\n",
    "where $\\mathbf{z}^{(0)}=\\mathbf{x}$ and $\\mathbf{z}\\in \\mathbb{R}^p$.\n",
    "- Depth: $L$, number of hidden layers\n",
    "- Width: $p$, number of neurons per layer\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./figures/MLP_full.png\" width=\"700\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fafd8b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MLP as Composition of Functions\n",
    "\n",
    "If we write $f(\\mathbf{z}^{(l-1)},\\color{red}{\\mathbf{W}^{(l)}} ) =\\phi\\left(\\color{red}{\\mathbf{W}^{(l)}}\\,\\mathbf{z}^{(l-1)} + \\color{red}{\\mathbf{b}^{(l)}}\\right)$ (dropping the offset $\\color{red}{\\mathbf{b}^{(l)}}$ for ease of bookkeeping), we can see that \n",
    "$$ \\mathbf{z}^{(l)} = f(\\mathbf{z}^{(l-1)},\\color{red}{\\mathbf{W}^{(l)}} )=f(f(\\mathbf{z}^{(l-2)},\\color{red}{\\mathbf{W}^{(l-1)}} ),\\color{red}{\\mathbf{W}^{(l)}} ) = ...  $$\n",
    "\n",
    "Here $f(g(x))$ is the composition of two functions $f$ and $g$:\n",
    "$${\\rm Let} \\quad u=g(x)\\quad {\\rm then}\\quad f(g(x))=f(u) $$\n",
    "\n",
    "\n",
    "Try out different perceptrons with **linear** activation in [Tensorflow playground](https://playground.tensorflow.org/) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b2be9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linearity + Non‑Linearity  \n",
    "\n",
    "Stacking linear layers without nonlinear activation is not helpful!  \n",
    "\n",
    "Observation: composition of **linear** mappings is still a **linear** mapping. \n",
    "$$ \\color{red}{\\mathbf{W}^{(2)}}\\left(\\color{red}{\\mathbf{W}^{(1)}}\\mathbf{x} + \\color{red}{\\mathbf{b}^{(1)}}\\right)+ \\color{red}{\\mathbf{b}^{(2)}} = \\color{red}{\\mathbf{W}^{(2)}\\mathbf{W}^{(1)}}\\mathbf{x} +  \\color{red}{\\mathbf{W}^{(2)}\\mathbf{b}^{(1)}+ \\mathbf{b}^{(2)}} =  \\color{red}{\\mathbf{W}'}\\mathbf{x}+\\color{red}{\\mathbf{b}'},$$\n",
    "where $ \\mathbf{W}'\\equiv \\mathbf{W}^{(2)}\\mathbf{W}^{(1)}$ and $\\mathbf{b}'\\equiv \\mathbf{W}^{(2)}\\mathbf{b}^{(1)}+ \\mathbf{b}^{(2)}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58b688",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Common Non‑Linear Activation Functions\n",
    "\n",
    "Here are the three most common activation functions:\n",
    "-  **ReLU**: rectified linear unit $\\max(0,z)$\n",
    "- <span style=\"color:red\">Sigmoid</span>: $1/(1+e^{-z}) $\n",
    "- <span style=\"color:orange\">Tanh</span>:  $\\tanh(z)=\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$ \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./figures/activation.png\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Try out different perceptrons with **nonlinear** activation in [Tensorflow playground](https://playground.tensorflow.org/) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19516a1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MLP as a Universal Approximator\n",
    "\n",
    "Fact: A **single hidden layer** MLP with enough neurons can approximate *any* continuous function on a compact set ([Cybenko 1989](https://link.springer.com/article/10.1007/BF02551274)).  \n",
    "\n",
    "Practical take‑aways:  \n",
    "* Depth is **not** required for approximation.  \n",
    "* Deep, *narrow* nets are far more parameter‑efficient.  \n",
    "* Deep hierarchies capture **compositional structure** (i.e., features build on features).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd22c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training MLPs: Loss Function\n",
    "\n",
    "\n",
    "Given inputs $\\mathbf{x}$ and label $y$, we want to find a loss function to evaluate the model\n",
    "\n",
    "$$\\mathcal{L}(\\theta)=\\frac{1}{N}\\sum_i \\ell\\bigl(f(\\mathbf{x}_i;\\theta),\\,y_i\\bigr)$$  \n",
    "\n",
    "Here we use $\\theta$ to represent the collection of $\\mathbf{W}^{(1)}$, $\\mathbf{b}^{(1)}$, $\\mathbf{W}^{(2)}$, $\\mathbf{b}^{(2)}$, ...\n",
    "\n",
    "- Common choices: MSE for regression, cross-entropy for classification.\n",
    "\n",
    "- Regularizers: we might add $\\ell_2$-norm as penalty on $\\theta$, use dropout in training...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b7c94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training MLPs: Optimization\n",
    "\n",
    "Given the loss function $\\mathcal{L}(\\theta)$, we want to find $\\hat{\\theta}$ that minimizes the loss\n",
    "$$ \\hat{\\theta}= \\underset{\\theta}{\\arg \\min} \\mathcal{L}(\\theta).$$\n",
    "\n",
    "This type of problem is known as an *optimization* problem\n",
    "\n",
    "Common algorithms: \n",
    "- **Gradient descent**, nesterov accelerated gradient, adaptive Gradient Algorithm, adaptive Moment Estimation, root Mean Square Propagation, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68a9d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization in Modern Deep Learning\n",
    "\n",
    "| Model (year)                            | Training cost               | Number of parameters |\n",
    "| --------------------------------------- | ---------------------------------------------------------------------- |--------------- |\n",
    "| GPT-5 (2025, in progress)           | \"500 million\"               ([1](https://www.fanaticalfuturist.com/2025/05/openai-gpt-5-is-costing-500-million-per-training-run-and-still-failing/)) | 5 trillion |\n",
    "| GPT-4 (2023)                        | “More than 100 million”                                         ([2](https://www.reuters.com/breakingviews/ai-firms-lead-quest-intelligent-business-model-2023-12-12/?utm_source=chatgpt.com))            | 1.8 trillion |\n",
    "| Gemini Ultra (Google, 2023)         | \"Close to 200 million\"    ([3](https://techcrunch.com/2025/02/25/anthropics-latest-flagship-ai-might-not-have-been-incredibly-costly-to-train/))         | 1.56 trillion| \n",
    "| Claude 3.7 Sonnet (Anthropic, 2025) | “A few tens of millions”                                  ([3](https://techcrunch.com/2025/02/25/anthropics-latest-flagship-ai-might-not-have-been-incredibly-costly-to-train/))         | 70 - 150 billion |\n",
    "| Llama 3 (Meta, 2024)                | “At least 500 million\" ([4](https://www.pymnts.com/artificial-intelligence-2/2025/ai-cheat-sheet-large-language-foundation-model-training-costs/))  | 405 billion|\n",
    "| <span style=\"color:red\">Human brain (300,000 BCE)</span>          | <span style=\"color:red\">???</span>  | <span style=\"color:red\">86 billion (neurons)</span> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2b6e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Iterate till convergence \n",
    "$$\\theta^{(k)} \\leftarrow \\theta^{(k-1)} - \\eta\\,\\nabla_\\theta \\mathcal{L} \\mid_{\\theta = \\theta^{(k-1)}}$$  \n",
    "\n",
    "- $\\eta$: learning‑rate, step size.  \n",
    "- $\\nabla_\\theta \\mathcal{L}$: gradient* of $\\mathcal{L}$ with respect to $\\theta$ \n",
    "- $\\nabla_\\theta \\mathcal{L}\\mid_{\\theta = \\theta^{(k-1)}}$: ... evaluated at $\\theta^{(k-1)}$\n",
    "- Convergence: $\\|\\theta^{(k)}-\\theta^{(k-1)}\\|_2 \\leq \\epsilon$ ($\\epsilon$ is a user-specified threshold)\n",
    "\n",
    " *:Roughly speaking, a ratio of the following form  [the change in $\\mathcal{L}$ given an incremental change in $\\theta$] / [the incremental change in $\\theta$]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f9b9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent: Examples\n",
    "\n",
    "\n",
    "Calculate the first three gradient updates by hand:\n",
    "$$\\hat{\\theta}= \\underset{\\theta}{\\arg \\min} (y - x\\theta)^2,$$\n",
    "where $y=10$ and $x=2$. \n",
    "- $\\nabla_\\theta \\mathcal{L} = 2 x (x\\theta -y)$\n",
    "- $\\theta^{(0)}=6$\n",
    "- $\\eta = 0.01$ \n",
    "\n",
    "<!-- Gradients: 8, 1.6, 0.32, 0.064; theta: 5.2, 5.04, 5.008, 5.0016, 5.00032 -->\n",
    "\n",
    "We should be able to work out the solution easily. It might be even easier without using GD!\n",
    "\n",
    "> [Additional not-so-easy examples](vscode://file//Users/shizhe/Documents/Github/Website(Public)/Gradient_Descent_examples.ipynb) if time permits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95075d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stochastic Gradient Descent  \n",
    "\n",
    "Recall that $ \\mathcal{L}(\\theta)=\\frac{1}{N}\\sum_i \\ell\\bigl(f(\\mathbf{x}_i;\\theta),\\,y_i\\bigr)$\n",
    "\n",
    "Each update of gradient descent has to go through all $N$ observations -- might be too costly for big data! \n",
    "\n",
    "Stochastic Gradient Descent: calculate gradients on mini-batches\n",
    "\n",
    "Iterate till convergence \n",
    "\n",
    "- Randomly draw $n$ observations with indices $\\{j_1,j_2,\\ldots,j_n\\}$\n",
    "- Update $\\theta^{(k)}$ \n",
    "$$\\theta^{(k)} \\leftarrow \\theta^{(k-1)} - \\frac{\\eta}{n}\\,\\sum_{i=1}^n \\nabla_\\theta \\ell\\bigl(f(\\mathbf{x}_{j_i};\\theta),\\,y_{j_i}\\bigr)$$  \n",
    "\n",
    "> [SGD exercise](vscode://file//Users/shizhe/Documents/Github/Website(Public)/Gradient_Descent_examples.ipynb) if time permits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527fb1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backpropogation\n",
    "\n",
    "- In the exercise, we have already found the challenges in deriving gradients (by-hand)\n",
    "\n",
    "- For deep neural networks with many hidden layers, it is infeasible to derive the gradients by hand\n",
    "\n",
    "- A better idea is to use the chain-rule in calculous, let $z=g(\\theta)$ \n",
    "$$ \\frac{\\partial f(g(\\theta))}{\\partial \\theta} = \\frac{\\partial f}{\\partial z} \\frac{\\partial g}{\\partial \\theta} $$\n",
    "\n",
    "- Backpropogation helps break down the task of finding gradients of complicated composite functions into manageable, commonly-used gradients.\n",
    "\n",
    "- More examples in [Lecture 4](https://cs231n.stanford.edu/slides/2024/lecture_4.pdf) of Stanford CS231n by Fei-Fei Li et al. (starting from Page 57)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27242f60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training MLPs\n",
    "\n",
    "- Training MLPs are fairly straightforward thanks to existing librarys \n",
    "- Popular libraries: TensorFlow, PyTorch\n",
    "- Play with [an example using California Housing Data](vscode://file//Users/shizhe/Documents/Github/Website(Public)/MLP.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
