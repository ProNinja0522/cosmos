{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ed7c46",
   "metadata": {},
   "source": [
    "# ‚ö°Ô∏è AdaBoost Regression\n",
    "\n",
    "## üìñ What Is AdaBoost?\n",
    "\n",
    "**AdaBoost (Adaptive Boosting)** is an ensemble method that combines multiple **weak learners** (typically shallow decision trees) by adaptively adjusting their weights based on how well they perform on the training data.\n",
    "\n",
    "Unlike Gradient Boosting, which fits residuals using gradient descent, **AdaBoost adjusts the weights of the training data points**: harder-to-predict points receive more focus in the next iteration.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Key Ideas\n",
    "\n",
    "- Weak learners are trained sequentially.\n",
    "- After each round, examples with higher errors are given **more weight**.\n",
    "- The final prediction is a **weighted sum** of all weak learners.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Key Parameters (in `AdaBoostRegressor`)\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `n_estimators` | Number of boosting rounds |\n",
    "| `learning_rate` | Shrinks contribution of each regressor |\n",
    "| `base_estimator` | Typically a shallow `DecisionTreeRegressor` |\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Simulated Example\n",
    "\n",
    "We fit:\n",
    "\n",
    "\\[\n",
    "y = \\sin(2\\pi x) + \\varepsilon\n",
    "\\]\n",
    "\n",
    "and compare AdaBoost to other methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98dc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Simulated data\n",
    "np.random.seed(0)\n",
    "X = np.sort(np.random.rand(100, 1), axis=0)\n",
    "y = np.sin(2 * np.pi * X).ravel() + np.random.normal(0, 0.2, size=100)\n",
    "X_plot = np.linspace(0, 1, 500).reshape(-1, 1)\n",
    "\n",
    "# Fit AdaBoost\n",
    "ada = AdaBoostRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=4),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5,\n",
    "    random_state=0\n",
    ")\n",
    "ada.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "y_pred = ada.predict(X_plot)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X, y, s=20, label=\"Data\")\n",
    "plt.plot(X_plot, y_pred, color=\"red\", label=\"AdaBoost Prediction\")\n",
    "plt.title(\"AdaBoost Regression on Simulated Data\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc1a6a",
   "metadata": {},
   "source": [
    "## üè† Real Data: California Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Load data\n",
    "data = fetch_california_housing()\n",
    "X_real = data.data\n",
    "y_real = data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_real, y_real, test_size=0.2, random_state=1)\n",
    "\n",
    "# Fit AdaBoost\n",
    "ada_real = AdaBoostRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=4),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.5,\n",
    "    random_state=1\n",
    ")\n",
    "ada_real.fit(X_train, y_train)\n",
    "y_pred_real = ada_real.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"R^2: {r2_score(y_test, y_pred_real):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_real):.4f}\")\n",
    "\n",
    "# Plot predicted vs. true\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(y_test, y_pred_real, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.title(\"AdaBoost Regression on California Housing\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6443fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = ada_real.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title(\"Feature Importance from AdaBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
