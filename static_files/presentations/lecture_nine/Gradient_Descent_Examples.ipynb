{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8bdf5b",
   "metadata": {},
   "source": [
    "# Gradient Descent Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c819f",
   "metadata": {},
   "source": [
    "Solve the following optimization problems using gradient descent. If you are stuck or just want to check the solution, you can use the prompt after each problem to obtain example code from co-pilot (keep in mind that LLM might make mistakes!).\n",
    "\n",
    "> Additional question: Write one function with optional arguments that can handle all three problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab23168",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "Optimization problem: \n",
    "$$\\hat{\\theta}= \\underset{\\theta}{\\arg \\min}  \\left[ y - \\max(0, \\theta x) \\right]^2,$$\n",
    "where $y=10$ and $x=2$. \n",
    "- Here use $\\theta^{(0)}=3$ and $\\eta = 0.1$. \n",
    "- Let the convergence threshold be $10^{-4}$\n",
    "- (Sub) Gradient:\n",
    "$$\n",
    "\\nabla\\mathcal{L}(\\theta) =\n",
    "\\begin{cases}\n",
    "-(y - \\theta x) \\cdot x, & \\text{if } \\theta x > 0 \\\\\n",
    "0, & \\text{if } \\theta x \\le 0\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd02c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to use to reveal the code:\n",
    "# Write a python script that solves the following problem using gradient descent: $$\\hat{\\theta}= \\underset{\\theta}{\\arg \\min}  \\left[ y - \\max(0, \\theta x) \\right]^2,$$ where $y=10$ and $x=2$. Here $\\theta^{(0)}=3$ and $\\eta = 0.1$. Let the convergence threshold be $10^{-4}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5766c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: \n",
    "# Note: the minimizer should be $\\hat{\\theta} = 5$ with possible numerical errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a79234",
   "metadata": {},
   "source": [
    "### Question 2 \n",
    "\n",
    "Optimization problem\n",
    "$$\n",
    "\\hat{\\theta}= \\underset{\\theta}{\\arg \\min} \\left( y - \\frac{1}{1+\\exp(-\\theta x)} \\right)^2,\n",
    "$$\n",
    "where $y=0.3$ and $x=2$. \n",
    "\n",
    "- Here $\\theta^{(0)}=0$ and $\\eta = 0.1$. \n",
    "- Let the convergence threshold be $10^{-4}$\n",
    "- Gradient:\n",
    "$$\n",
    "\\nabla\\mathcal{L}(\\theta) = - (y - \\sigma(\\theta x)) \\cdot \\sigma(\\theta x) \\cdot (1 - \\sigma(\\theta x)) \\cdot x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1e6c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to use to reveal the code:\n",
    "# Write a python script that solves the following problem using gradient descent: Optimization problem $$\\mathcal{L}_\\text{Sigmoid}(\\theta) = \\frac{1}{2} \\left( y - \\frac{1}{1+\\exp(-\\theta x)} \\right)^2,$$ where $y=0.3$ and $x=0$.  Here $\\theta^{(0)}=0$ and $\\eta = 0.1$. Let the convergence threshold be $10^{-4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45adc731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: \n",
    "# Note: the minimizer should be around -0.42 with possible numerical errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7346dd",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Optimization problem\n",
    "$$\n",
    "\\hat{\\theta}= \\underset{\\theta}{\\arg \\min} \\left[ y - \\tanh(\\theta x) \\right]^2,\n",
    "$$ \n",
    "where $\\tanh(\\theta x)=\\frac{e^{\\theta x}-e^{-\\theta x}}{e^{\\theta x}+e^{-\\theta x}}$,  $y=0.3$ and $x=2$. \n",
    "- Here $\\theta^{(0)}=0$ and $\\eta = 0.1$. \n",
    "- Let the convergence threshold be $10^{-4}$\n",
    "- Gradient:\n",
    "$$\n",
    "\\nabla\\mathcal{L}(\\theta) = - [y - \\tanh(\\theta x)] \\cdot [1 - \\tanh^2(\\theta x)] \\cdot x\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7664af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to use to reveal the code:\n",
    "# Write a python script that solves the following problem using gradient descent:  $$\\hat{\\theta}= \\underset{\\theta}{\\arg \\min} \\left[ y - \\tanh(\\theta x) \\right]^2,$$  where $\\tanh(\\theta x)=\\frac{e^{\\theta x}-e^{-\\theta x}}{e^{\\theta x}+e^{-\\theta x}}$,  $y=0.3$ and $x=2$. Here $\\theta^{(0)}=0$ and $\\eta = 0.1$. Let the convergence threshold be $10^{-4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: \n",
    "# Note: the minimizer should be around 0.155 with possible numerical errors.\n",
    "# helpful function: np.tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba6189",
   "metadata": {},
   "source": [
    "## Question 4: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093604e8",
   "metadata": {},
   "source": [
    "Optimization problem: \n",
    "$$\\hat{\\theta}= \\underset{\\theta}{\\arg \\min}  \\frac{1}{2N} \\sum_{i=1}^N \\left[ y_i - \\max(0, \\theta x_i) \\right]^2,$$\n",
    "where $\\{(x_i,y_i)\\}_{i=1}^N$ are generated in the cell below. The rest of the setup is the same with that of Question 1. \n",
    "\n",
    "Tasks:\n",
    "1. Use gradient descent to find solve the problem; denote the optimal solution as $\\hat{\\theta}_{\\rm GD}$\n",
    "2. Use stochastic gradient descent with mini-batch size $n=10$ to find $\\hat{\\theta}_{\\rm SGD}$\n",
    "\n",
    "> Optional: Try a range of $n$ from $5$ to $50$ and compare the number of iterations and/or computing time each algorithm takes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5417d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation:\n",
    "# True theta = 8\n",
    "import numpy as np\n",
    "\n",
    "# Settings\n",
    "np.random.seed(42)\n",
    "N = 100  # sample size c\n",
    "true_theta = 8\n",
    "noise_std = 0.5\n",
    "\n",
    "x = np.random.randn(N)  # x_i ~ N(0,1)\n",
    "noise = np.random.normal(0, noise_std, N)\n",
    "y = np.maximum(0, true_theta * x) + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de7a8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to use to reveal the code:\n",
    "# Write a python script that solves the following problem using stochastic gradient descent with batch size 20: $$\\hat{\\theta}= \\underset{\\theta}{\\arg \\min}  \\frac{1}{2N} \\sum_{i=1}^N \\left[ y_i - \\max(0, \\theta x_i) \\right]^2,$$ where $\\{(x_i,y_i)\\}_{i=1}^N$ are generated and saved in x and y with N=100. Here $\\theta^{(0)}=0$ and $\\eta = 0.1$. Let the convergence threshold be $10^{-4}$  Here $\\theta^{(0)}=3$ and $\\eta = 0.1$. Let the convergence threshold be $10^{-4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12159d04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
